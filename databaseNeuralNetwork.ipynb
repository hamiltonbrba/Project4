{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Data/diabetes_binary_5050split_health_indicators_BRFSS2023.csv'\n",
    "df_new = pd.read_csv(file_path)\n",
    "\n",
    "# Create an SQLite database and save the dataset\n",
    "conn = sqlite3.connect('diabetes_data.db')  # Creates a file-based SQLite database\n",
    "df_new.to_sql('diabetes_data', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_binary  HighBP  HighChol  CholCheck  BMI  PhysActivity  \\\n",
      "0              0.0     0.0       0.0        2.0  3.0           2.0   \n",
      "1              0.0     0.0       0.0        3.0  3.0           1.0   \n",
      "2              0.0     1.0       1.0        2.0  3.0           1.0   \n",
      "3              0.0     0.0       1.0        2.0  3.0           9.0   \n",
      "4              0.0     1.0       0.0        2.0  2.0           1.0   \n",
      "\n",
      "   LastCheckup  Smoker  CHCKDNY2  Stroke  ...  AnyHealthcare  NoDocbcCost  \\\n",
      "0          1.0     4.0       2.0     0.0  ...            1.0          0.0   \n",
      "1          1.0     4.0       2.0     0.0  ...            1.0          0.0   \n",
      "2          1.0     3.0       2.0     0.0  ...            1.0          0.0   \n",
      "3          1.0     4.0       2.0     0.0  ...            1.0          0.0   \n",
      "4          1.0     1.0       2.0     0.0  ...            1.0          0.0   \n",
      "\n",
      "   GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
      "0      2.0       3.0       0.0       0.0  1.0   1.0        4.0     8.0  \n",
      "1      2.0       0.0       0.0       0.0  0.0   3.0        4.0    11.0  \n",
      "2      1.0       0.0       0.0       0.0  1.0  11.0        6.0    10.0  \n",
      "3      2.0       2.0      10.0       0.0  1.0   4.0        6.0    10.0  \n",
      "4      4.0       0.0       0.0       1.0  1.0   9.0        6.0     9.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Query data from the SQL database\n",
    "query = \"SELECT * FROM diabetes_data\"\n",
    "df_sql = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_sql.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Data/diabetes_binary_5050split_health_indicators_BRFSS2023.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Diabetes_binary'])  # Replace 'Diabetes_binary' with your target column\n",
    "y = df['Diabetes_binary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# One-hot encode categorical columns (if any)\n",
    "if not categorical_columns.empty:\n",
    "    X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTETomek to balance the training data\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Hamilton-Brown\\anaconda3\\envs\\DataViz2\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_dim=X_train_balanced.shape[1]),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.5627 - val_accuracy: 0.7481 - val_loss: 0.5152\n",
      "Epoch 2/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7567 - loss: 0.5050 - val_accuracy: 0.7486 - val_loss: 0.5139\n",
      "Epoch 3/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7613 - loss: 0.4963 - val_accuracy: 0.7482 - val_loss: 0.5107\n",
      "Epoch 4/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7609 - loss: 0.4911 - val_accuracy: 0.7514 - val_loss: 0.5130\n",
      "Epoch 5/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7705 - loss: 0.4852 - val_accuracy: 0.7509 - val_loss: 0.5108\n",
      "Epoch 6/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.4894 - val_accuracy: 0.7502 - val_loss: 0.5096\n",
      "Epoch 7/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7681 - loss: 0.4866 - val_accuracy: 0.7493 - val_loss: 0.5088\n",
      "Epoch 8/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7639 - loss: 0.4902 - val_accuracy: 0.7487 - val_loss: 0.5115\n",
      "Epoch 9/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7675 - loss: 0.4855 - val_accuracy: 0.7511 - val_loss: 0.5077\n",
      "Epoch 10/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7714 - loss: 0.4797 - val_accuracy: 0.7526 - val_loss: 0.5091\n",
      "Epoch 11/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7699 - loss: 0.4812 - val_accuracy: 0.7518 - val_loss: 0.5075\n",
      "Epoch 12/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7662 - loss: 0.4868 - val_accuracy: 0.7504 - val_loss: 0.5098\n",
      "Epoch 13/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7695 - loss: 0.4812 - val_accuracy: 0.7514 - val_loss: 0.5083\n",
      "Epoch 14/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7690 - loss: 0.4815 - val_accuracy: 0.7497 - val_loss: 0.5074\n",
      "Epoch 15/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7669 - loss: 0.4863 - val_accuracy: 0.7505 - val_loss: 0.5138\n",
      "Epoch 16/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7722 - loss: 0.4783 - val_accuracy: 0.7518 - val_loss: 0.5075\n",
      "Epoch 17/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7674 - loss: 0.4816 - val_accuracy: 0.7510 - val_loss: 0.5106\n",
      "Epoch 18/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7720 - loss: 0.4781 - val_accuracy: 0.7511 - val_loss: 0.5077\n",
      "Epoch 19/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7699 - loss: 0.4804 - val_accuracy: 0.7510 - val_loss: 0.5101\n",
      "Epoch 20/20\n",
      "\u001b[1m1457/1457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7710 - loss: 0.4807 - val_accuracy: 0.7514 - val_loss: 0.5071\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    epochs=20, batch_size=32, validation_data=(X_test_scaled, y_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636us/step\n",
      "Accuracy: 0.7514030164854437\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74     11404\n",
      "         1.0       0.73      0.80      0.76     11404\n",
      "\n",
      "    accuracy                           0.75     22808\n",
      "   macro avg       0.75      0.75      0.75     22808\n",
      "weighted avg       0.75      0.75      0.75     22808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype('int32')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataViz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
