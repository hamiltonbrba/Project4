{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73592"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/diabetes_binary_5050split_health_indicators_BRFSS2023.csv'\n",
    "df_new = pd.read_csv(file_path)\n",
    "\n",
    "# Create an SQLite database and save the dataset\n",
    "conn = sqlite3.connect('diabetes_data.db')  # Creates a file-based SQLite database\n",
    "df_new.to_sql('diabetes_data', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_binary  HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  \\\n",
      "0              0.0     0.0       0.0        0.0  2.0     0.0     0.0   \n",
      "1              0.0     0.0       0.0        0.0  3.0     0.0     0.0   \n",
      "2              0.0     1.0       0.0        0.0  4.0     1.0     0.0   \n",
      "3              0.0     0.0       0.0        4.0  3.0     1.0     0.0   \n",
      "4              0.0     0.0       0.0        0.0  4.0     1.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  HvyAlcoholConsump  AnyHealthcare  \\\n",
      "0                   0.0           1.0                0.0            1.0   \n",
      "1                   0.0           1.0                0.0            1.0   \n",
      "2                   1.0           1.0                0.0            1.0   \n",
      "3                   0.0           1.0                0.0            0.0   \n",
      "4                   0.0           1.0                0.0            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      3.0       4.0       4.0       0.0  0.0   3.0        6.0   \n",
      "1          0.0      3.0       2.0       3.0       0.0  1.0   8.0        6.0   \n",
      "2          0.0      2.0       0.0       0.0       1.0  0.0  13.0        5.0   \n",
      "3          1.0      3.0       4.0       0.0       1.0  0.0   6.0        5.0   \n",
      "4          0.0      2.0       0.0       0.0       0.0  1.0   8.0        4.0   \n",
      "\n",
      "   Income  \n",
      "0    11.0  \n",
      "1     9.0  \n",
      "2    10.0  \n",
      "3     7.0  \n",
      "4     8.0  \n"
     ]
    }
   ],
   "source": [
    "# Query data from the SQL database\n",
    "query = \"SELECT * FROM diabetes_data\"\n",
    "df_sql = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_sql.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/diabetes_binary_5050split_health_indicators_BRFSS2023.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Diabetes_binary'])  # Replace 'Diabetes_binary' with your target column\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "# Check for categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# One-hot encode categorical columns (if any)\n",
    "if not categorical_columns.empty:\n",
    "    X = pd.get_dummies(X, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTETomek to balance the training set\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote_tomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_dim = X_train_balanced.shape[1]\n",
    "num_classes = len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bryan Hamilton-Brown\\anaconda3\\envs\\DataViz2\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_dim=input_dim),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')  # For multiclass classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7660 - loss: 0.4876 - val_accuracy: 0.7403 - val_loss: 0.5231\n",
      "Epoch 2/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7683 - loss: 0.4858 - val_accuracy: 0.7398 - val_loss: 0.5228\n",
      "Epoch 3/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7665 - loss: 0.4888 - val_accuracy: 0.7399 - val_loss: 0.5253\n",
      "Epoch 4/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7648 - loss: 0.4905 - val_accuracy: 0.7401 - val_loss: 0.5237\n",
      "Epoch 5/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7612 - loss: 0.4891 - val_accuracy: 0.7406 - val_loss: 0.5241\n",
      "Epoch 6/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7687 - loss: 0.4824 - val_accuracy: 0.7419 - val_loss: 0.5240\n",
      "Epoch 7/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7631 - loss: 0.4867 - val_accuracy: 0.7406 - val_loss: 0.5224\n",
      "Epoch 8/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7620 - loss: 0.4880 - val_accuracy: 0.7376 - val_loss: 0.5250\n",
      "Epoch 9/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7685 - loss: 0.4858 - val_accuracy: 0.7385 - val_loss: 0.5273\n",
      "Epoch 10/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7664 - loss: 0.4855 - val_accuracy: 0.7382 - val_loss: 0.5238\n",
      "Epoch 11/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7624 - loss: 0.4864 - val_accuracy: 0.7404 - val_loss: 0.5228\n",
      "Epoch 12/100\n",
      "\u001b[1m1536/1536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7679 - loss: 0.4858 - val_accuracy: 0.7395 - val_loss: 0.5286\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_balanced, pd.get_dummies(y_train_balanced),\n",
    "    epochs=100, batch_size=32,\n",
    "    validation_data=(X_test_scaled, pd.get_dummies(y_test)),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step\n",
      "Accuracy: 0.7405562098016125\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.66      0.71     10604\n",
      "         1.0       0.72      0.82      0.77     11474\n",
      "\n",
      "    accuracy                           0.74     22078\n",
      "   macro avg       0.74      0.74      0.74     22078\n",
      "weighted avg       0.74      0.74      0.74     22078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataViz2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
